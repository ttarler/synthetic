{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple SageMaker AI-Enhanced Fraud Data Generation\n",
    "\n",
    "This notebook demonstrates SageMaker AI-enhanced fraud data generation without Neptune dependencies.\n",
    "\n",
    "## Workflow:\n",
    "1. **Generate 100K base transactions** using enhanced fraud logic\n",
    "2. **Train SageMaker models** (RandomCutForest + XGBoost) on local data\n",
    "3. **Generate AI-enhanced transactions** using trained endpoints\n",
    "4. **Save results locally** for analysis or further use\n",
    "\n",
    "## Benefits:\n",
    "- âœ… **Portable**: Runs in any AWS account\n",
    "- âœ… **Simple**: No VPC or Neptune setup required\n",
    "- âœ… **Cost-effective**: Only SageMaker training/endpoint costs\n",
    "- âœ… **Focused**: Pure ML enhancement demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Authentication and Setup\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Try different authentication methods in order of preference\n",
    "print(\"ğŸ” Setting up AWS authentication...\")\n",
    "\n",
    "session = None\n",
    "auth_method = None\n",
    "\n",
    "# Method 1: Try SageMaker execution role (for SageMaker notebook instances)\n",
    "try:\n",
    "    from sagemaker import get_execution_role\n",
    "    role = get_execution_role()\n",
    "    session = boto3.Session()\n",
    "    # Test the session\n",
    "    session.client('sts').get_caller_identity()\n",
    "    auth_method = \"SageMaker IAM Role\"\n",
    "    print(f\"âœ… Using SageMaker execution role: {role}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Method 2: Try default AWS credentials (CLI, environment variables, IAM role)\n",
    "if not session:\n",
    "    try:\n",
    "        session = boto3.Session()\n",
    "        # Test the session\n",
    "        session.client('sts').get_caller_identity()\n",
    "        auth_method = \"AWS Default Credentials\"\n",
    "        print(\"âœ… Using AWS default credentials (CLI/environment/IAM role)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Method 3: Manual credentials (if needed)\n",
    "if not session:\n",
    "    print(\"âŒ No AWS credentials found\")\n",
    "    print(\"\\nğŸ”§ Setup options:\")\n",
    "    print(\"   1. Run 'aws configure' in terminal\")\n",
    "    print(\"   2. Set environment variables: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\")\n",
    "    print(\"   3. Use IAM role if running on EC2/SageMaker\")\n",
    "    print(\"\\nğŸ’¡ For workshop/temporary credentials, set environment variables:\")\n",
    "    print(\"\")\n",
    "    print(\"# Option A: Set in terminal before starting notebook:\")\n",
    "    print(\"# export AWS_ACCESS_KEY_ID='your_access_key'\")\n",
    "    print(\"# export AWS_SECRET_ACCESS_KEY='your_secret_key'\")\n",
    "    print(\"# export AWS_SESSION_TOKEN='your_session_token'  # For temporary credentials\")\n",
    "    print(\"# export AWS_DEFAULT_REGION='us-west-2'\")\n",
    "    print(\"\")\n",
    "    print(\"# Option B: Set in notebook (less secure):\")\n",
    "    print(\"# os.environ['AWS_ACCESS_KEY_ID'] = 'your_access_key'\")\n",
    "    print(\"# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_key'\")\n",
    "    print(\"# os.environ['AWS_SESSION_TOKEN'] = 'your_session_token'\")\n",
    "    print(\"# os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\")\n",
    "    print(\"# session = boto3.Session()  # Then retry\")\n",
    "    raise Exception(\"AWS credentials not configured\")\n",
    "\n",
    "# Get AWS account information\n",
    "try:\n",
    "    account_id = session.client('sts').get_caller_identity()['Account']\n",
    "    region = session.region_name or 'us-west-2'  # Default region if not set\n",
    "    print(f\"\\nâœ… AWS Authentication successful!\")\n",
    "    print(f\"   Method: {auth_method}\")\n",
    "    print(f\"   Account ID: {account_id}\")\n",
    "    print(f\"   Region: {region}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ AWS authentication failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules and verify setup\n",
    "# Add src directory to path\n",
    "sys.path.append('src')\n",
    "\n",
    "try:\n",
    "    from enhanced_fraud_generator import EnhancedFraudGenerator\n",
    "    from sagemaker_fraud_enhancer import SageMakerFraudEnhancer\n",
    "    print(\"âœ… Project modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"\\nğŸ”§ Make sure you're running this notebook from the correct directory\")\n",
    "    print(\"   The 'src' folder should be in the same directory as this notebook\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nğŸ¤– Simple SageMaker AI-Enhanced Fraud Generator\")\n",
    "print(f\"SageMaker Version: {sagemaker.__version__}\")\n",
    "print(\"\\nâœ… Ready for AI-enhanced fraud generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Base Dataset (100K Transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the enhanced fraud generator\n",
    "print(\"ğŸ­ Initializing Enhanced Fraud Generator...\")\n",
    "generator = EnhancedFraudGenerator('config/enhanced_fraud_rules.yaml')\n",
    "\n",
    "# Generate complete fraud network\n",
    "print(\"\\nğŸ“Š Generating enhanced fraud network...\")\n",
    "print(\"This includes:\")\n",
    "print(\"   â€¢ 9 different fraud types\")\n",
    "print(\"   â€¢ Realistic financial institutions\")\n",
    "print(\"   â€¢ Complex fraud patterns\")\n",
    "print(\"   â€¢ Risk scoring\")\n",
    "print(\"\\nâ±ï¸  This may take 2-3 minutes...\")\n",
    "\n",
    "# Generate the network data\n",
    "network_data = generator.generate_network()\n",
    "transactions = network_data['transactions'].to_dict('records')\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(transactions):,} base transactions!\")\n",
    "\n",
    "# Quick analysis\n",
    "df = pd.DataFrame(transactions)\n",
    "fraud_count = len(df[df['is_fraud'] == True])\n",
    "print(f\"\\nğŸ“ˆ Dataset Summary:\")\n",
    "print(f\"   â€¢ Total transactions: {len(df):,}\")\n",
    "print(f\"   â€¢ Fraud transactions: {fraud_count:,}\")\n",
    "print(f\"   â€¢ Fraud rate: {fraud_count/len(df)*100:.1f}%\")\n",
    "print(f\"   â€¢ Institutions: {network_data['institutions'].shape[0]}\")\n",
    "print(f\"   â€¢ Accounts: {network_data['accounts'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save Base Dataset Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the base dataset for SageMaker training\n",
    "print(\"ğŸ’¾ Saving base dataset locally...\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'base_dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save transactions\n",
    "transactions_df = pd.DataFrame(transactions)\n",
    "transactions_df.to_csv(f'{output_dir}/transactions.csv', index=False)\n",
    "\n",
    "# Save institutions and accounts from network data\n",
    "institutions_df = network_data['institutions']\n",
    "institutions = institutions_df.to_dict('records')\n",
    "institutions_df.to_csv(f'{output_dir}/institutions.csv', index=False)\n",
    "\n",
    "accounts_df = network_data['accounts']\n",
    "accounts = accounts_df.to_dict('records')\n",
    "accounts_df.to_csv(f'{output_dir}/accounts.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Base dataset saved to {output_dir}/:\")\n",
    "print(f\"   â€¢ transactions.csv ({len(transactions):,} records)\")\n",
    "print(f\"   â€¢ institutions.csv ({len(institutions)} records)\")\n",
    "print(f\"   â€¢ accounts.csv ({len(accounts)} records)\")\n",
    "print(\"\\nğŸ“Š Ready for SageMaker training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train SageMaker Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker AI enhancer\n",
    "print(\"ğŸ¤– Initializing SageMaker AI Enhancer...\")\n",
    "sagemaker_enhancer = SageMakerFraudEnhancer()\n",
    "\n",
    "# Load the base dataset\n",
    "print(\"\\nğŸ“‚ Loading base dataset for SageMaker training...\")\n",
    "sagemaker_enhancer.load_existing_data('base_dataset')\n",
    "\n",
    "print(\"\\nâœ… Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SageMaker models\n",
    "print(\"ğŸš€ Training SageMaker models...\")\n",
    "print(\"\\nThis will:\")\n",
    "print(\"   â€¢ Create S3 bucket for SageMaker\")\n",
    "print(\"   â€¢ Upload training data to S3\")\n",
    "print(\"   â€¢ Train Random Cut Forest for anomaly detection\")\n",
    "print(\"   â€¢ Train XGBoost for fraud classification\")\n",
    "print(\"   â€¢ Deploy both models as endpoints\")\n",
    "print(\"\\nâ±ï¸  Expected time: 10-15 minutes\")\n",
    "print(\"ğŸ’° Cost: ~$2-3 for training + ~$0.10/hour for endpoints\")\n",
    "\n",
    "# Execute training\n",
    "sagemaker_enhancer.train_sagemaker_models()\n",
    "\n",
    "print(\"\\nâœ… SageMaker models trained and deployed successfully!\")\n",
    "print(\"\\nğŸ¯ Ready for AI-enhanced transaction generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate AI-Enhanced Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate AI-enhanced transactions\n",
    "print(\"ğŸ¯ Generating AI-enhanced transactions...\")\n",
    "print(\"\\nğŸ“Š SageMaker enhancements include:\")\n",
    "print(\"   â€¢ Random Cut Forest anomaly detection\")\n",
    "print(\"   â€¢ XGBoost fraud classification\")\n",
    "print(\"   â€¢ Real-time endpoint inference\")\n",
    "print(\"   â€¢ Enterprise-grade ML models\")\n",
    "print(\"\\nâ±ï¸  This may take 5-8 minutes for 30K transactions...\")\n",
    "\n",
    "# Generate enhanced transactions\n",
    "enhanced_count = 30000\n",
    "ai_transactions = sagemaker_enhancer.generate_ai_enhanced_transactions(enhanced_count)\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(ai_transactions):,} AI-enhanced transactions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze AI-Enhanced Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the AI-enhanced dataset\n",
    "ai_df = pd.DataFrame(ai_transactions)\n",
    "\n",
    "print(f\"ğŸ“ˆ AI-Enhanced Dataset Analysis:\")\n",
    "print(f\"  Total AI Transactions: {len(ai_df):,}\")\n",
    "\n",
    "# Fraud statistics\n",
    "ai_fraud_df = ai_df[ai_df['is_fraud'] == True]\n",
    "print(f\"\\nğŸš¨ AI Fraud Statistics:\")\n",
    "print(f\"  AI Fraud Transactions: {len(ai_fraud_df):,}\")\n",
    "print(f\"  AI Fraud Rate: {len(ai_fraud_df)/len(ai_df)*100:.2f}%\")\n",
    "\n",
    "# AI-specific metrics\n",
    "print(f\"\\nğŸ¤– SageMaker Enhancement Metrics:\")\n",
    "print(f\"  Average AI Confidence: {ai_df['ai_confidence'].mean():.3f}\")\n",
    "print(f\"  Average Pattern Similarity: {ai_df['pattern_similarity'].mean():.3f}\")\n",
    "print(f\"  Generation Method: {ai_df['generation_method'].iloc[0]}\")\n",
    "\n",
    "# Compare with base dataset\n",
    "base_fraud_rate = fraud_count / len(df) * 100\n",
    "ai_fraud_rate = len(ai_fraud_df) / len(ai_df) * 100\n",
    "\n",
    "print(f\"\\nğŸ“Š Comparison:\")\n",
    "print(f\"  Base Dataset Fraud Rate: {base_fraud_rate:.2f}%\")\n",
    "print(f\"  AI-Enhanced Fraud Rate: {ai_fraud_rate:.2f}%\")\n",
    "print(f\"  Enhancement Factor: {ai_fraud_rate/base_fraud_rate:.2f}x\")\n",
    "\n",
    "# Show sample transactions\n",
    "print(\"\\nğŸ’¸ Sample AI-Enhanced Transactions:\")\n",
    "display(ai_df[['transaction_id', 'amount', 'fraud_type', 'ai_confidence', 'generation_method']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save AI-Enhanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AI-enhanced dataset\n",
    "print(\"ğŸ’¾ Saving AI-enhanced dataset...\")\n",
    "\n",
    "# Save enhanced data\n",
    "sagemaker_enhancer.save_sagemaker_enhanced_data(ai_transactions, 'ai_enhanced_output')\n",
    "\n",
    "print(\"\\nâœ… AI-enhanced dataset saved successfully!\")\n",
    "print(\"\\nğŸ“ Output files:\")\n",
    "print(\"   â€¢ ai_enhanced_output/transactions.csv - AI-enhanced transactions\")\n",
    "print(\"   â€¢ ai_enhanced_output/institutions.csv - Institution data\")\n",
    "print(\"   â€¢ ai_enhanced_output/accounts.csv - Account data\")\n",
    "print(\"   â€¢ ai_enhanced_output/sagemaker_summary.json - Enhancement summary\")\n",
    "\n",
    "# Show file sizes\n",
    "import os\n",
    "for file in ['transactions.csv', 'institutions.csv', 'accounts.csv', 'sagemaker_summary.json']:\n",
    "    path = f'ai_enhanced_output/{file}'\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path)\n",
    "        print(f\"   ğŸ“„ {file}: {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Cleanup SageMaker endpoints to avoid ongoing charges\n",
    "print(\"ğŸ’° SageMaker Endpoint Cleanup\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\\nâš ï¸  SageMaker endpoints cost ~$0.10/hour each when running\")\n",
    "print(\"   Cleanup is recommended when done with the workshop\")\n",
    "\n",
    "print(\"\\nğŸ§¹ To cleanup endpoints, uncomment and run:\")\n",
    "print(\"# sagemaker_enhancer.cleanup_endpoints()\")\n",
    "\n",
    "print(\"\\nğŸ“Š Or check current endpoints:\")\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "try:\n",
    "    endpoints = sagemaker_client.list_endpoints()['Endpoints']\n",
    "    if endpoints:\n",
    "        print(\"\\nğŸ“‹ Current SageMaker endpoints:\")\n",
    "        for ep in endpoints:\n",
    "            print(f\"   â€¢ {ep['EndpointName']} - {ep['EndpointStatus']}\")\n",
    "    else:\n",
    "        print(\"\\nâœ… No active endpoints found\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Could not list endpoints: {e}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember: Endpoints can be recreated from saved models if needed later\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Simple SageMaker AI Enhancement Completed:**\n",
    "1. Generated enhanced fraud network with institutions, accounts, and transactions\n",
    "2. Trained RandomCutForest for anomaly detection\n",
    "3. Trained XGBoost for fraud classification\n",
    "4. Generated 30,000 AI-enhanced transactions\n",
    "5. Saved all results locally for analysis\n",
    "\n",
    "ğŸ¤– **SageMaker Benefits Demonstrated:**\n",
    "- **Enterprise ML**: Production-ready anomaly detection and classification\n",
    "- **Scalability**: Can handle millions of transactions\n",
    "- **Real-time**: Live endpoint inference for fraud scoring\n",
    "- **Portability**: Runs in any AWS account without VPC setup\n",
    "\n",
    "ğŸ’° **Cost Summary:**\n",
    "- Training: ~$2-3 per session\n",
    "- Endpoints: ~$0.10/hour each (remember to cleanup!)\n",
    "- Storage: Minimal S3 costs\n",
    "\n",
    "ğŸ“Š **Next Steps:**\n",
    "- Analyze AI-enhanced transaction patterns\n",
    "- Compare fraud detection accuracy\n",
    "- Scale to larger datasets\n",
    "- Integrate with production systems\n",
    "- Add Neptune for graph analysis (optional)\n",
    "\n",
    "ğŸ¯ **Integration Ready:**\n",
    "This simplified approach can easily be extended with:\n",
    "- Neptune graph database (add VPC when needed)\n",
    "- QuickSight dashboards\n",
    "- Real-time streaming\n",
    "- Production ML pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}