{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Enhanced Fraud Data Generation\n",
    "\n",
    "This notebook demonstrates how to use AI to learn from existing fraud data and generate additional sophisticated fraud transactions. The AI learns patterns from the original 100,000 transactions and creates 30,000 new AI-enhanced transactions.\n",
    "\n",
    "## AI Enhancement Process\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Existing 100K Transactions] --> B[AI Pattern Learning]\n",
    "    B --> C[Fraud Pattern Analysis]\n",
    "    B --> D[Amount Prediction Models]\n",
    "    B --> E[Anomaly Detection Training]\n",
    "    C --> F[Generate 30K AI Transactions]\n",
    "    D --> F\n",
    "    E --> F\n",
    "    F --> G[Incremental Neptune Loading]\n",
    "    \n",
    "    style A fill:#e1f5fe\n",
    "    style F fill:#f3e5f5\n",
    "    style G fill:#e8f5e8\n",
    "```\n",
    "\n",
    "## What You'll Build\n",
    "- **Pattern Learning**: AI learns from existing fraud patterns\n",
    "- **Amount Prediction**: Smart transaction amount generation\n",
    "- **Anomaly Detection**: Enhanced risk scoring\n",
    "- **AI Confidence Metrics**: Quality assessment of generated data\n",
    "- **Incremental Loading**: Add to existing Neptune data\n",
    "\n",
    "**Prerequisites**: Run `Enhanced_Fraud_Bulk_Load_Workflow.ipynb` first to generate the base 100K transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph notebook extensions\n",
    "%load_ext graph_notebook.magics\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from src.ai_learning_enhancer import AILearningEnhancer\n",
    "from src.neptune_bulk_loader import NeptuneBulkLoader\n",
    "\n",
    "# Auto-detect configuration\n",
    "session = boto3.Session()\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = session.region_name\n",
    "\n",
    "print(\"ü§ñ AI-Enhanced Fraud Data Generator - Ready!\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "# Configuration\n",
    "NEPTUNE_ENDPOINT = os.environ.get('NEPTUNE_ENDPOINT', 'UPDATE-ME.cluster-xyz.us-west-2.neptune.amazonaws.com')\n",
    "S3_BUCKET = f\"{account_id}-neptune-bulk-load\"\n",
    "NEPTUNE_ROLE_ARN = f\"arn:aws:iam::{account_id}:role/neptune-workbench-NeptuneS3AccessRole\"\n",
    "\n",
    "print(f\"\\nNeptune Endpoint: {NEPTUNE_ENDPOINT}\")\n",
    "if 'UPDATE-ME' in NEPTUNE_ENDPOINT:\n",
    "    print('‚ö†Ô∏è  UPDATE NEPTUNE_ENDPOINT above with your actual Neptune cluster endpoint')\n",
    "else:\n",
    "    print('‚úÖ Ready for AI enhancement!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Validate Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AI Learning Enhancer\n",
    "ai_enhancer = AILearningEnhancer()\n",
    "\n",
    "# Load existing dataset (will error if not found)\n",
    "try:\n",
    "    ai_enhancer.load_existing_data('enhanced_output')\n",
    "    print(\"\\n‚úÖ Successfully loaded existing dataset!\")\n",
    "    print(\"   Ready to proceed with AI enhancement.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    print(\"\\nüîß Solution: Run 'Enhanced_Fraud_Bulk_Load_Workflow.ipynb' first to generate base data.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Unexpected error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train AI Models on Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AI models on the existing 100K transactions\n",
    "print(\"üéì Training AI models on existing fraud patterns...\")\n",
    "print(\"This will:\")\n",
    "print(\"   ‚Ä¢ Learn fraud type distributions and patterns\")\n",
    "print(\"   ‚Ä¢ Train amount prediction models\")\n",
    "print(\"   ‚Ä¢ Build anomaly detection for risk scoring\")\n",
    "print(\"   ‚Ä¢ Analyze timing patterns for each fraud type\")\n",
    "print(\"\\n‚è±Ô∏è  This may take 1-2 minutes...\")\n",
    "\n",
    "ai_enhancer.train_ai_models()\n",
    "\n",
    "print(\"\\n‚úÖ AI training complete! Models are ready to generate enhanced transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate AI-Enhanced Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30,000 AI-enhanced transactions\n",
    "print(\"üéØ Generating 30,000 AI-enhanced transactions...\")\n",
    "print(\"üìä AI enhancements include:\")\n",
    "print(\"   ‚Ä¢ Learned fraud patterns from existing data\")\n",
    "print(\"   ‚Ä¢ Smart amount prediction based on fraud types\")\n",
    "print(\"   ‚Ä¢ Optimal timing based on historical patterns\")\n",
    "print(\"   ‚Ä¢ Enhanced risk scoring with anomaly detection\")\n",
    "print(\"   ‚Ä¢ AI confidence and pattern similarity metrics\")\n",
    "print(\"\\n‚è±Ô∏è  This may take 2-3 minutes...\")\n",
    "\n",
    "# Generate AI-enhanced transactions\n",
    "ai_transactions = ai_enhancer.generate_ai_enhanced_transactions(30000)\n",
    "\n",
    "print(\"\\n‚úÖ AI-enhanced transaction generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Examine AI-Enhanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "ai_df = pd.DataFrame(ai_transactions)\n",
    "\n",
    "print(f\"üìà AI-Enhanced Data Summary:\")\n",
    "print(f\"  Total AI Transactions: {len(ai_df):,}\")\n",
    "\n",
    "# Fraud statistics\n",
    "ai_fraud_df = ai_df[ai_df['is_fraud'] == True]\n",
    "print(f\"\\nüö® AI Fraud Statistics:\")\n",
    "print(f\"  AI Fraud Transactions: {len(ai_fraud_df):,}\")\n",
    "print(f\"  AI Fraud Rate: {len(ai_fraud_df)/len(ai_df)*100:.2f}%\")\n",
    "\n",
    "# Show AI fraud type distribution\n",
    "print(f\"\\nüé≠ AI Fraud Types:\")\n",
    "ai_fraud_counts = ai_fraud_df['fraud_type'].value_counts()\n",
    "for fraud_type, count in ai_fraud_counts.items():\n",
    "    print(f\"  {fraud_type}: {count:,}\")\n",
    "\n",
    "# AI-specific metrics\n",
    "print(f\"\\nü§ñ AI Enhancement Metrics:\")\n",
    "print(f\"  Average AI Confidence: {ai_df['ai_confidence'].mean():.3f}\")\n",
    "print(f\"  Average Pattern Similarity: {ai_df['pattern_similarity'].mean():.3f}\")\n",
    "print(f\"  Generation Method: {ai_df['generation_method'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample AI-enhanced transactions\n",
    "print(\"üí∏ Sample AI-Enhanced Transactions:\")\n",
    "display(ai_df[['transaction_id', 'amount', 'fraud_type', 'ai_confidence', 'pattern_similarity', 'generation_method']].head())\n",
    "\n",
    "print(\"\\nüö® Sample AI-Enhanced Fraud Transactions:\")\n",
    "display(ai_fraud_df[['transaction_id', 'amount', 'fraud_type', 'risk_score', 'ai_confidence', 'pattern_similarity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save AI-Enhanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AI-enhanced data to separate folder\n",
    "print(\"üíæ Saving AI-enhanced data...\")\n",
    "\n",
    "ai_enhancer.save_ai_enhanced_data(ai_transactions, 'ai_enhanced_output')\n",
    "\n",
    "print(\"\\n‚úÖ AI-enhanced data saved successfully!\")\n",
    "print(\"   Files are ready for incremental Neptune bulk loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Incremental Bulk Load to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bulk loader for incremental loading\n",
    "bulk_loader = NeptuneBulkLoader(\n",
    "    neptune_endpoint=NEPTUNE_ENDPOINT,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    neptune_role_arn=NEPTUNE_ROLE_ARN\n",
    ")\n",
    "\n",
    "print(\"üåä Starting incremental bulk load to Neptune...\")\n",
    "print(\"This will:\")\n",
    "print(\"  1Ô∏è‚É£ Convert AI-enhanced data to Neptune CSV format\")\n",
    "print(\"  2Ô∏è‚É£ Upload to S3 bucket (separate prefix)\")\n",
    "print(\"  3Ô∏è‚É£ Start Neptune incremental bulk load job\")\n",
    "print(\"  4Ô∏è‚É£ Monitor progress until complete\")\n",
    "print(\"\\n‚è±Ô∏è  Total time: ~2-3 minutes for incremental loading\")\n",
    "print(\"\\nüìù Note: This will ADD the 30K transactions to existing 100K in Neptune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute incremental bulk load\n",
    "print(\"üöÄ Starting incremental bulk load to Neptune...\")\n",
    "\n",
    "# Use RESUME mode for incremental loading\n",
    "success = bulk_loader.bulk_load_enhanced_fraud_data('ai_enhanced_output')\n",
    "\n",
    "if success:\n",
    "    print(\"\\nüéâ SUCCESS: AI-enhanced transactions added to Neptune!\")\n",
    "    print(\"\\nüìä Final Data Status:\")\n",
    "    print(\"   ‚úÖ Original: 100,000 transactions (rule-based)\")\n",
    "    print(\"   ‚úÖ AI-Enhanced: 30,000 transactions (AI-generated)\")\n",
    "    print(\"   ‚úÖ Total in Neptune: 130,000 transactions\")\n",
    "    print(\"\\nüìä Next Steps:\")\n",
    "    print(\"   ‚Ä¢ Open 'Fraud_Detection_Analytics.ipynb' for analysis\")\n",
    "    print(\"   ‚Ä¢ Query both rule-based and AI-enhanced transactions\")\n",
    "    print(\"   ‚Ä¢ Compare AI confidence scores and patterns\")\n",
    "    print(\"   ‚Ä¢ Explore enhanced fraud detection capabilities\")\n",
    "else:\n",
    "    print(\"\\nüí• FAILED: Incremental bulk load unsuccessful.\")\n",
    "    print(\"Check Neptune logs and CloudFormation stack outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Neptune to verify total transaction count\n",
    "print(\"üîç Verifying combined dataset in Neptune...\")\n",
    "\n",
    "# Simple Gremlin query to count total transactions\n",
    "try:\n",
    "    %gremlin\n",
    "    g.E().hasLabel('PAYMENT').count()\n",
    "except:\n",
    "    print(\"Note: Run this cell manually to verify transaction count in Neptune\")\n",
    "    print(\"Expected result: 130,000 total transactions\")\n",
    "\n",
    "print(\"\\nüìä Dataset Composition:\")\n",
    "print(\"   ‚Ä¢ Rule-based transactions: ~100,000 (generation_method not set)\")\n",
    "print(\"   ‚Ä¢ AI-enhanced transactions: ~30,000 (generation_method = 'AI_Enhanced')\")\n",
    "print(\"   ‚Ä¢ Total fraud transactions: ~3,900 (3% of 130K)\")\n",
    "print(\"   ‚Ä¢ AI confidence scores: Available for AI-enhanced transactions\")\n",
    "print(\"   ‚Ä¢ Pattern similarity: Available for AI-enhanced transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **AI Enhancement Completed Successfully:**\n",
    "1. Loaded and validated existing 100,000 transactions\n",
    "2. Trained AI models on fraud patterns, amounts, and timing\n",
    "3. Generated 30,000 AI-enhanced transactions with learned patterns\n",
    "4. Added AI confidence and pattern similarity metrics\n",
    "5. Incrementally loaded to Neptune (total: 130,000 transactions)\n",
    "\n",
    "ü§ñ **AI Enhancements Added:**\n",
    "- **Pattern Learning**: Fraud types based on historical frequency\n",
    "- **Smart Amount Prediction**: Amounts based on learned distributions\n",
    "- **Timing Optimization**: Hours based on fraud-type patterns\n",
    "- **Anomaly Detection**: Enhanced risk scoring with ML\n",
    "- **Quality Metrics**: AI confidence and pattern similarity scores\n",
    "\n",
    "üìä **Next Steps:**\n",
    "- Analyze AI vs rule-based transaction patterns\n",
    "- Use AI confidence scores for fraud detection\n",
    "- Compare pattern similarity across fraud types\n",
    "- Build ML models on the enhanced 130K dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}